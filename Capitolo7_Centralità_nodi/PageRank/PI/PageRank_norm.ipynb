{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "genetic-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import useful libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import networkx as nx\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distinct-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"./EDGES_FILE.csv\", create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convenient-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "destroyed-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "l = list(nx.selfloop_edges(G))\n",
    "for x, _ in l:\n",
    "    if(G.degree(x) == 2): \n",
    "        G.remove_node(x)\n",
    "        nodes.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "million-potential",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "charged-excitement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calulated scores in: 0.9073235988616943\n"
     ]
    }
   ],
   "source": [
    "i_time = time.time()\n",
    "bet = nx.pagerank(G)\n",
    "print(f\"Calulated scores in: {time.time() - i_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "authorized-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_l = []\n",
    "for i in sorted(list(map(lambda x: int(x), bet.keys()))):\n",
    "    bet_norm = (bet[str(i)] - min(bet.values())) / (max(bet.values()) - min(bet.values())) \n",
    "    bet_l.append(bet_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-california",
   "metadata": {},
   "source": [
    "# 0.05 sized intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expected-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = []\n",
    "for bet_v in bet_l:\n",
    "    for i in range(1, 21):\n",
    "        if(bet_v <= 0.05 * i): \n",
    "            node_labels.append(i)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "colonial-argument",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     311\n",
       "2     179\n",
       "3      82\n",
       "4      57\n",
       "5      46\n",
       "6      27\n",
       "7      20\n",
       "8      16\n",
       "9      10\n",
       "10      8\n",
       "12      5\n",
       "11      5\n",
       "14      4\n",
       "13      4\n",
       "19      2\n",
       "15      1\n",
       "20      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(node_labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-celtic",
   "metadata": {},
   "source": [
    "### DW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suitable-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = 0\n",
    "with open(\"./dw/dw_info.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if \"Test\" in line: tests += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cheap-cylinder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration completed in 0.3543095588684082\n",
      "Iteration completed in 0.38189268112182617\n",
      "Iteration completed in 0.40067601203918457\n",
      "Iteration completed in 0.39165449142456055\n",
      "Iteration completed in 0.3582024574279785\n",
      "Iteration completed in 0.3560941219329834\n",
      "Iteration completed in 0.35494375228881836\n",
      "Iteration completed in 0.387345552444458\n",
      "Iteration completed in 0.4285311698913574\n",
      "Iteration completed in 0.36562228202819824\n",
      "Iteration completed in 0.3504488468170166\n",
      "Iteration completed in 0.3730461597442627\n",
      "Iteration completed in 0.41281747817993164\n",
      "Iteration completed in 0.34911060333251953\n",
      "Iteration completed in 0.36880946159362793\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "f1_scores = []\n",
    "for i in range(tests):\n",
    "    start_time = time.time()\n",
    "    data = pd.read_csv(\"./dw/dw_emb_vectors\" + str(i) + \".csv\", header=None, sep=\";\").values.tolist()\n",
    "    # Input \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), data))\n",
    "    X_data = [X_data[i] for i in range(len(X_data)) if str(i + 1) not in nodes]\n",
    "    \n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    print(f\"Iteration completed in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dress-central",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15.000000\n",
       "mean      0.415385\n",
       "std       0.069684\n",
       "min       0.333333\n",
       "25%       0.355769\n",
       "50%       0.410256\n",
       "75%       0.442308\n",
       "max       0.570513\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(f1_scores).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-clone",
   "metadata": {},
   "source": [
    "### N2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "exact-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = 0\n",
    "with open(\"./n2v/n2v_info.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if \"Test\" in line: tests += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "searching-remainder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration completed in 0.44329214096069336\n",
      "Iteration completed in 0.4456775188446045\n",
      "Iteration completed in 0.4383671283721924\n",
      "Iteration completed in 0.45079565048217773\n",
      "Iteration completed in 0.48334622383117676\n",
      "Iteration completed in 0.4698023796081543\n",
      "Iteration completed in 0.42504310607910156\n",
      "Iteration completed in 0.44639134407043457\n",
      "Iteration completed in 0.42966771125793457\n",
      "Iteration completed in 0.4371674060821533\n",
      "Iteration completed in 0.44211912155151367\n",
      "Iteration completed in 0.5249383449554443\n",
      "Iteration completed in 0.44618678092956543\n",
      "Iteration completed in 0.4815387725830078\n",
      "Iteration completed in 0.44428205490112305\n",
      "Iteration completed in 0.4655330181121826\n",
      "Iteration completed in 0.5114521980285645\n",
      "Iteration completed in 0.4480862617492676\n",
      "Iteration completed in 0.419126033782959\n",
      "Iteration completed in 0.4262208938598633\n",
      "Iteration completed in 0.46944212913513184\n",
      "Iteration completed in 0.4470548629760742\n",
      "Iteration completed in 0.5006203651428223\n",
      "Iteration completed in 0.46271800994873047\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "f1_scores = []\n",
    "for i in range(tests):\n",
    "    start_time = time.time()\n",
    "    data = pd.read_csv(\"./n2v/n2v_emb_vectors\" + str(i) + \".csv\", header=None, sep=\";\").values.tolist()\n",
    "    # Input \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), data))\n",
    "    X_data = [X_data[i] for i in range(len(X_data)) if str(i + 1) not in nodes]\n",
    "    \n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    print(f\"Iteration completed in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "configured-joseph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24.000000\n",
       "mean      0.442041\n",
       "std       0.055994\n",
       "min       0.307692\n",
       "25%       0.421474\n",
       "50%       0.435897\n",
       "75%       0.477564\n",
       "max       0.557692\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(f1_scores).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-marketing",
   "metadata": {},
   "source": [
    "### MNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "exceptional-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = 0\n",
    "with open(\"./mnmf/mnmf_info.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if \"Test\" in line: tests += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "senior-success",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration completed in 0.18442296981811523\n",
      "Iteration completed in 0.1443800926208496\n",
      "Iteration completed in 0.2022252082824707\n",
      "Iteration completed in 0.1674809455871582\n",
      "Iteration completed in 0.20355701446533203\n",
      "Iteration completed in 0.1739799976348877\n",
      "Iteration completed in 0.26006460189819336\n",
      "Iteration completed in 0.19372105598449707\n",
      "Iteration completed in 0.2930772304534912\n",
      "Iteration completed in 0.2545437812805176\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "f1_scores = []\n",
    "for i in range(tests):\n",
    "    start_time = time.time()\n",
    "    data = pd.read_csv(\"./mnmf/mnmf_emb_vectors\" + str(i) + \".csv\", header=None, sep=\";\").values.tolist()\n",
    "    # Input \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), data))\n",
    "    X_data = [X_data[i] for i in range(len(X_data)) if str(i + 1) not in nodes]\n",
    "    \n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    print(f\"Iteration completed in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wooden-floor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10.000000\n",
       "mean      0.372436\n",
       "std       0.044355\n",
       "min       0.294872\n",
       "25%       0.341346\n",
       "50%       0.371795\n",
       "75%       0.399038\n",
       "max       0.442308\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(f1_scores).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-genome",
   "metadata": {},
   "source": [
    "# Heterogeneous intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "threatened-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = []\n",
    "for bet_v in bet_l:\n",
    "    ok = False\n",
    "    for i in range(1, 11):\n",
    "        if(bet_v <= 0.005 * i): \n",
    "            node_labels.append(i)\n",
    "            ok = True\n",
    "            break\n",
    "    if ok: continue\n",
    "    for i in range(1, 6):\n",
    "        if(bet_v <= 0.05 + 0.01 * i):\n",
    "            node_labels.append(10 + i)\n",
    "            ok = True\n",
    "            break\n",
    "    if ok: continue\n",
    "    if(bet_v <= 0.2):\n",
    "        node_labels.append(16)\n",
    "        continue\n",
    "    node_labels.append(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "relative-saint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    149\n",
       "16    139\n",
       "11     58\n",
       "2      42\n",
       "1      42\n",
       "12     36\n",
       "9      35\n",
       "5      35\n",
       "7      34\n",
       "13     32\n",
       "3      30\n",
       "15     30\n",
       "6      26\n",
       "8      26\n",
       "14     23\n",
       "10     22\n",
       "4      19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(node_labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-encoding",
   "metadata": {},
   "source": [
    "### DW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "clean-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = 0\n",
    "with open(\"./dw/dw_info.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if \"Test\" in line: tests += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "impressive-mortality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration completed in 0.36212873458862305\n",
      "Iteration completed in 0.3689277172088623\n",
      "Iteration completed in 0.4069633483886719\n",
      "Iteration completed in 0.415912389755249\n",
      "Iteration completed in 0.40134572982788086\n",
      "Iteration completed in 0.3751096725463867\n",
      "Iteration completed in 0.40749692916870117\n",
      "Iteration completed in 0.3890421390533447\n",
      "Iteration completed in 0.3742647171020508\n",
      "Iteration completed in 0.39904189109802246\n",
      "Iteration completed in 0.394960880279541\n",
      "Iteration completed in 0.3772733211517334\n",
      "Iteration completed in 0.41410040855407715\n",
      "Iteration completed in 0.4192328453063965\n",
      "Iteration completed in 0.4034121036529541\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "f1_scores = []\n",
    "for i in range(tests):\n",
    "    start_time = time.time()\n",
    "    data = pd.read_csv(\"./dw/dw_emb_vectors\" + str(i) + \".csv\", header=None, sep=\";\").values.tolist()\n",
    "    # Input \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), data))\n",
    "    \n",
    "    X_data = [X_data[i] for i in range(len(X_data)) if str(i + 1) not in nodes]\n",
    "    \n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    print(f\"Iteration completed in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "latter-transsexual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15.000000\n",
       "mean      0.250000\n",
       "std       0.043476\n",
       "min       0.192308\n",
       "25%       0.208333\n",
       "50%       0.250000\n",
       "75%       0.285256\n",
       "max       0.346154\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(f1_scores).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-holocaust",
   "metadata": {},
   "source": [
    "### n2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "invisible-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = 0\n",
    "with open(\"./n2v/n2v_info.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if \"Test\" in line: tests += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "irish-heating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration completed in 0.45911598205566406\n",
      "Iteration completed in 0.5042409896850586\n",
      "Iteration completed in 0.6048874855041504\n",
      "Iteration completed in 0.5467097759246826\n",
      "Iteration completed in 0.46938538551330566\n",
      "Iteration completed in 0.5464363098144531\n",
      "Iteration completed in 0.5016546249389648\n",
      "Iteration completed in 0.595038652420044\n",
      "Iteration completed in 0.509493350982666\n",
      "Iteration completed in 0.47056007385253906\n",
      "Iteration completed in 0.4753129482269287\n",
      "Iteration completed in 0.5772325992584229\n",
      "Iteration completed in 0.4831860065460205\n",
      "Iteration completed in 0.5410900115966797\n",
      "Iteration completed in 0.5261683464050293\n",
      "Iteration completed in 0.5559730529785156\n",
      "Iteration completed in 0.461575984954834\n",
      "Iteration completed in 0.5565006732940674\n",
      "Iteration completed in 0.48111486434936523\n",
      "Iteration completed in 0.48660826683044434\n",
      "Iteration completed in 0.49615979194641113\n",
      "Iteration completed in 0.5012013912200928\n",
      "Iteration completed in 0.49604272842407227\n",
      "Iteration completed in 0.41383790969848633\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "f1_scores = []\n",
    "for i in range(tests):\n",
    "    start_time = time.time()\n",
    "    data = pd.read_csv(\"./n2v/n2v_emb_vectors\" + str(i) + \".csv\", header=None, sep=\";\").values.tolist()\n",
    "    # Input \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), data))\n",
    "    \n",
    "    X_data = [X_data[i] for i in range(len(X_data)) if str(i + 1) not in nodes]\n",
    "    \n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    print(f\"Iteration completed in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "hollywood-solid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24.000000\n",
       "mean      0.258013\n",
       "std       0.032645\n",
       "min       0.192308\n",
       "25%       0.240385\n",
       "50%       0.262821\n",
       "75%       0.282051\n",
       "max       0.314103\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(f1_scores).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-antibody",
   "metadata": {},
   "source": [
    "### MNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cardiovascular-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = 0\n",
    "with open(\"./mnmf/mnmf_info.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if \"Test\" in line: tests += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "square-error",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration completed in 0.1792755126953125\n",
      "Iteration completed in 0.12824773788452148\n",
      "Iteration completed in 0.20001983642578125\n",
      "Iteration completed in 0.15227055549621582\n",
      "Iteration completed in 0.2061614990234375\n",
      "Iteration completed in 0.1539909839630127\n",
      "Iteration completed in 0.22612619400024414\n",
      "Iteration completed in 0.1838381290435791\n",
      "Iteration completed in 0.32134532928466797\n",
      "Iteration completed in 0.22861623764038086\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "f1_scores = []\n",
    "for i in range(tests):\n",
    "    start_time = time.time()\n",
    "    data = pd.read_csv(\"./mnmf/mnmf_emb_vectors\" + str(i) + \".csv\", header=None, sep=\";\").values.tolist()\n",
    "    # Input \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), data))\n",
    "    X_data = [X_data[i] for i in range(len(X_data)) if str(i + 1) not in nodes]\n",
    "    \n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    print(f\"Iteration completed in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "specialized-cuisine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10.000000\n",
       "mean      0.215385\n",
       "std       0.037034\n",
       "min       0.166667\n",
       "25%       0.184295\n",
       "50%       0.211538\n",
       "75%       0.246795\n",
       "max       0.275641\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(f1_scores).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-nirvana",
   "metadata": {},
   "source": [
    "# Heterogeneous pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cognitive-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = []\n",
    "for bet_v in bet_l:\n",
    "    start_val = 0.0001\n",
    "    i = 1\n",
    "    while(True):\n",
    "        if bet_v <= start_val:\n",
    "            node_labels.append(i)\n",
    "            break\n",
    "        else:\n",
    "            i += 1\n",
    "            start_val *= 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "inside-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    107\n",
       "18    100\n",
       "16     90\n",
       "20     84\n",
       "19     79\n",
       "21     64\n",
       "15     59\n",
       "22     41\n",
       "13     31\n",
       "14     28\n",
       "12     24\n",
       "23     19\n",
       "11     14\n",
       "9       9\n",
       "10      8\n",
       "1       7\n",
       "8       4\n",
       "24      3\n",
       "7       3\n",
       "6       2\n",
       "5       1\n",
       "4       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(node_labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-juvenile",
   "metadata": {},
   "source": [
    "### DW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "professional-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = 0\n",
    "with open(\"./dw/dw_info.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if \"Test\" in line: tests += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "wanted-bridges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration completed in 0.34056854248046875\n",
      "Iteration completed in 0.33775758743286133\n",
      "Iteration completed in 0.3386092185974121\n",
      "Iteration completed in 0.38820576667785645\n",
      "Iteration completed in 0.3239400386810303\n",
      "Iteration completed in 0.360095739364624\n",
      "Iteration completed in 0.38738155364990234\n",
      "Iteration completed in 0.3567829132080078\n",
      "Iteration completed in 0.3655729293823242\n",
      "Iteration completed in 0.35634541511535645\n",
      "Iteration completed in 0.31862378120422363\n",
      "Iteration completed in 0.31715917587280273\n",
      "Iteration completed in 0.3492605686187744\n",
      "Iteration completed in 0.3495168685913086\n",
      "Iteration completed in 0.3321115970611572\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "f1_scores = []\n",
    "for i in range(tests):\n",
    "    start_time = time.time()\n",
    "    data = pd.read_csv(\"./dw/dw_emb_vectors\" + str(i) + \".csv\", header=None, sep=\";\").values.tolist()\n",
    "    # Input \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), data))\n",
    "    \n",
    "    X_data = [X_data[i] for i in range(len(X_data)) if str(i + 1) not in nodes]\n",
    "    \n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    print(f\"Iteration completed in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "significant-washer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15.000000\n",
       "mean      0.195299\n",
       "std       0.043264\n",
       "min       0.115385\n",
       "25%       0.169872\n",
       "50%       0.198718\n",
       "75%       0.217949\n",
       "max       0.262821\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(f1_scores).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-grade",
   "metadata": {},
   "source": [
    "### n2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "small-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = 0\n",
    "with open(\"./n2v/n2v_info.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if \"Test\" in line: tests += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "local-rebecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration completed in 0.4037504196166992\n",
      "Iteration completed in 0.4237029552459717\n",
      "Iteration completed in 0.48894810676574707\n",
      "Iteration completed in 0.46711087226867676\n",
      "Iteration completed in 0.400134801864624\n",
      "Iteration completed in 0.4282186031341553\n",
      "Iteration completed in 0.46228766441345215\n",
      "Iteration completed in 0.45159173011779785\n",
      "Iteration completed in 0.4017024040222168\n",
      "Iteration completed in 0.4266784191131592\n",
      "Iteration completed in 0.4306297302246094\n",
      "Iteration completed in 0.49134349822998047\n",
      "Iteration completed in 0.4301762580871582\n",
      "Iteration completed in 0.47010254859924316\n",
      "Iteration completed in 0.45470428466796875\n",
      "Iteration completed in 0.4846374988555908\n",
      "Iteration completed in 0.42327260971069336\n",
      "Iteration completed in 0.4246492385864258\n",
      "Iteration completed in 0.42391419410705566\n",
      "Iteration completed in 0.4178769588470459\n",
      "Iteration completed in 0.43336057662963867\n",
      "Iteration completed in 0.4458785057067871\n",
      "Iteration completed in 0.42458295822143555\n",
      "Iteration completed in 0.4548344612121582\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "f1_scores = []\n",
    "for i in range(tests):\n",
    "    start_time = time.time()\n",
    "    data = pd.read_csv(\"./n2v/n2v_emb_vectors\" + str(i) + \".csv\", header=None, sep=\";\").values.tolist()\n",
    "    # Input \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), data))\n",
    "    \n",
    "    X_data = [X_data[i] for i in range(len(X_data)) if str(i + 1) not in nodes]\n",
    "    \n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    print(f\"Iteration completed in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "after-spiritual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24.000000\n",
       "mean      0.186165\n",
       "std       0.034828\n",
       "min       0.115385\n",
       "25%       0.166667\n",
       "50%       0.192308\n",
       "75%       0.211538\n",
       "max       0.243590\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(f1_scores).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-forth",
   "metadata": {},
   "source": [
    "### MNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bibliographic-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = 0\n",
    "with open(\"./mnmf/mnmf_info.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if \"Test\" in line: tests += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "uniform-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration completed in 0.1682109832763672\n",
      "Iteration completed in 0.1261141300201416\n",
      "Iteration completed in 0.27951693534851074\n",
      "Iteration completed in 0.16361117362976074\n",
      "Iteration completed in 0.1800229549407959\n",
      "Iteration completed in 0.21317648887634277\n",
      "Iteration completed in 0.2538766860961914\n",
      "Iteration completed in 0.20438814163208008\n",
      "Iteration completed in 0.28815770149230957\n",
      "Iteration completed in 0.21579289436340332\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "f1_scores = []\n",
    "for i in range(tests):\n",
    "    start_time = time.time()\n",
    "    data = pd.read_csv(\"./mnmf/mnmf_emb_vectors\" + str(i) + \".csv\", header=None, sep=\";\").values.tolist()\n",
    "    # Input \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), data))\n",
    "    \n",
    "    X_data = [X_data[i] for i in range(len(X_data)) if str(i + 1) not in nodes]\n",
    "    \n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    print(f\"Iteration completed in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "identified-skating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10.000000\n",
       "mean      0.180128\n",
       "std       0.031031\n",
       "min       0.153846\n",
       "25%       0.161859\n",
       "50%       0.166667\n",
       "75%       0.187500\n",
       "max       0.256410\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(f1_scores).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
