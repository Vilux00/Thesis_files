{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "genetic-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import useful libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import networkx as nx\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distinct-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"./edges_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "charged-excitement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed pagerank in: 30.147184133529663\n"
     ]
    }
   ],
   "source": [
    "i_time = time.time()\n",
    "bet = nx.pagerank(G)\n",
    "print(f\"Computed pagerank in: {time.time() - i_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "authorized-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_l = []\n",
    "max_v = max(bet.values())\n",
    "min_v = min(bet.values())\n",
    "for i in range(1, len(bet) + 1):\n",
    "    bet_norm = (bet[str(i)] - min_v) / (max_v - min_v) \n",
    "    bet_l.append(bet_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "miniature-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(range(0, 10)) + list(range(10, 30, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-genome",
   "metadata": {},
   "source": [
    "# Heterogeneous intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "threatened-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = []\n",
    "for bet_v in bet_l:\n",
    "    ok = False\n",
    "    for i in range(1, 11):\n",
    "        if(bet_v <= 0.005 * i): \n",
    "            node_labels.append(i)\n",
    "            ok = True\n",
    "            break\n",
    "    if ok: continue\n",
    "    for i in range(1, 6):\n",
    "        if(bet_v <= 0.05 + 0.01 * i):\n",
    "            node_labels.append(10 + i)\n",
    "            ok = True\n",
    "            break\n",
    "    if ok: continue\n",
    "    if(bet_v <= 0.2):\n",
    "        node_labels.append(16)\n",
    "        continue\n",
    "    node_labels.append(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "relative-saint",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     158355\n",
       "2       6524\n",
       "3       1529\n",
       "4        587\n",
       "5        312\n",
       "6        188\n",
       "7        114\n",
       "8         81\n",
       "16        77\n",
       "9         70\n",
       "11        64\n",
       "10        53\n",
       "12        47\n",
       "13        37\n",
       "17        32\n",
       "15        25\n",
       "14        19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(node_labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-heritage",
   "metadata": {},
   "source": [
    "### AVPRA all feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regional-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.read_pickle(\"./All_feat/log_trial_0_LPStates.pickled\") + pd.read_pickle(\"./All_feat/log_trial_1_LPStates.pickled\")[1:] + \\\n",
    "    pd.read_pickle(\"./All_feat/log_trial_2_LPStates.pickled\")[1:] + pd.read_pickle(\"./All_feat/log_trial_3_LPStates.pickled\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indian-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = [obj[i] for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "industrial-saskatchewan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed iteration in 2.6748414039611816\n",
      "Completed iteration in 9.186293601989746\n",
      "Completed iteration in 49.772648334503174\n",
      "Completed iteration in 47.48737597465515\n",
      "Completed iteration in 49.91695761680603\n",
      "Completed iteration in 47.5269033908844\n",
      "Completed iteration in 51.45666003227234\n",
      "Completed iteration in 46.05638003349304\n",
      "Completed iteration in 47.022024393081665\n",
      "Completed iteration in 45.344332456588745\n",
      "Completed iteration in 47.08179998397827\n",
      "Completed iteration in 49.83602261543274\n",
      "Completed iteration in 50.85501003265381\n",
      "Completed iteration in 50.79762840270996\n",
      "Completed iteration in 50.53306555747986\n",
      "Completed iteration in 55.408421993255615\n",
      "Completed iteration in 61.13941407203674\n",
      "Completed iteration in 83.37274479866028\n",
      "Completed iteration in 173.64308714866638\n",
      "Completed iteration in 188.39622282981873\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "\n",
    "f1_scores_all_1 = []\n",
    "for res in obj:\n",
    "    start_time = time.time()\n",
    "   \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), res[1]))\n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores_all_1.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    \n",
    "    print(f\"Completed iteration in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-flash",
   "metadata": {},
   "source": [
    "### AVPRA only lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adopted-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "running-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.read_pickle(\"./Only_lang/log_trial_0_LPStates.pickled\") + pd.read_pickle(\"./Only_lang/log_trial_1_LPStates.pickled\")[1:] + \\\n",
    "    pd.read_pickle(\"./Only_lang/log_trial_2_LPStates.pickled\")[1:] + pd.read_pickle(\"./Only_lang/log_trial_3_LPStates.pickled\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vocational-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = [obj[i] for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "superb-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed iteration in 2.3594810962677\n",
      "Completed iteration in 6.246383428573608\n",
      "Completed iteration in 44.73842763900757\n",
      "Completed iteration in 42.1638298034668\n",
      "Completed iteration in 43.96728277206421\n",
      "Completed iteration in 40.94746994972229\n",
      "Completed iteration in 42.12675380706787\n",
      "Completed iteration in 41.21927785873413\n",
      "Completed iteration in 40.98764085769653\n",
      "Completed iteration in 41.88897156715393\n",
      "Completed iteration in 41.29587912559509\n",
      "Completed iteration in 41.00460648536682\n",
      "Completed iteration in 41.34976601600647\n",
      "Completed iteration in 41.99521446228027\n",
      "Completed iteration in 41.344868421554565\n",
      "Completed iteration in 43.32020902633667\n",
      "Completed iteration in 41.75895643234253\n",
      "Completed iteration in 43.02928566932678\n",
      "Completed iteration in 46.468817949295044\n",
      "Completed iteration in 55.403444051742554\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "\n",
    "f1_scores_only_1 = []\n",
    "for res in obj:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), res[1]))\n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores_only_1.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    \n",
    "    print(f\"Completed iteration in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-nirvana",
   "metadata": {},
   "source": [
    "# Heterogeneous pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cognitive-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = []\n",
    "for bet_v in bet_l:\n",
    "    start_val = 0.0001\n",
    "    i = 1\n",
    "    while(True):\n",
    "        if bet_v <= start_val:\n",
    "            node_labels.append(i)\n",
    "            break\n",
    "        else:\n",
    "            i += 1\n",
    "            start_val *= 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "inside-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     23107\n",
       "8     21904\n",
       "6     21459\n",
       "5     17279\n",
       "9     17164\n",
       "4     13011\n",
       "1     12160\n",
       "10    11682\n",
       "3      9367\n",
       "11     6817\n",
       "2      6408\n",
       "12     3680\n",
       "13     1950\n",
       "14      968\n",
       "15      514\n",
       "16      274\n",
       "17      160\n",
       "18       98\n",
       "19       63\n",
       "20       26\n",
       "21       14\n",
       "22        4\n",
       "24        3\n",
       "23        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(node_labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-midnight",
   "metadata": {},
   "source": [
    "### AVPRA all feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exciting-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "equivalent-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.read_pickle(\"./All_feat/log_trial_0_LPStates.pickled\") + pd.read_pickle(\"./All_feat/log_trial_1_LPStates.pickled\")[1:] + \\\n",
    "    pd.read_pickle(\"./All_feat/log_trial_2_LPStates.pickled\")[1:] + pd.read_pickle(\"./All_feat/log_trial_3_LPStates.pickled\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "intelligent-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = [obj[i] for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "conceptual-ordinance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed iteration in 3.092564105987549\n",
      "Completed iteration in 13.548569440841675\n",
      "Completed iteration in 65.6003668308258\n",
      "Completed iteration in 70.37129282951355\n",
      "Completed iteration in 66.8019630908966\n",
      "Completed iteration in 70.06498265266418\n",
      "Completed iteration in 67.22136425971985\n",
      "Completed iteration in 71.7561867237091\n",
      "Completed iteration in 68.17057418823242\n",
      "Completed iteration in 72.73516726493835\n",
      "Completed iteration in 67.80450344085693\n",
      "Completed iteration in 70.23805594444275\n",
      "Completed iteration in 69.88181352615356\n",
      "Completed iteration in 72.5732524394989\n",
      "Completed iteration in 76.16222953796387\n",
      "Completed iteration in 78.33146500587463\n",
      "Completed iteration in 82.08087158203125\n",
      "Completed iteration in 100.15921425819397\n",
      "Completed iteration in 162.3116054534912\n",
      "Completed iteration in 167.76312136650085\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "\n",
    "f1_scores_all_2 = []\n",
    "for res in obj:\n",
    "    start_time = time.time()\n",
    "   \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), res[1]))\n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores_all_2.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    \n",
    "    print(f\"Completed iteration in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-emission",
   "metadata": {},
   "source": [
    "### AVPRA only lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "approximate-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "incoming-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.read_pickle(\"./Only_lang/log_trial_0_LPStates.pickled\") + pd.read_pickle(\"./Only_lang/log_trial_1_LPStates.pickled\")[1:] + \\\n",
    "    pd.read_pickle(\"./Only_lang/log_trial_2_LPStates.pickled\")[1:] + pd.read_pickle(\"./Only_lang/log_trial_3_LPStates.pickled\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pressed-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = [obj[i] for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bottom-fields",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed iteration in 2.7532527446746826\n",
      "Completed iteration in 8.799601554870605\n",
      "Completed iteration in 55.822981119155884\n",
      "Completed iteration in 60.128320932388306\n",
      "Completed iteration in 57.36158728599548\n",
      "Completed iteration in 59.590903520584106\n",
      "Completed iteration in 59.477296590805054\n",
      "Completed iteration in 61.048754930496216\n",
      "Completed iteration in 58.45052218437195\n",
      "Completed iteration in 58.6615035533905\n",
      "Completed iteration in 59.534000396728516\n",
      "Completed iteration in 58.760990381240845\n",
      "Completed iteration in 59.250404596328735\n",
      "Completed iteration in 62.17939853668213\n",
      "Completed iteration in 58.82445406913757\n",
      "Completed iteration in 57.70843839645386\n",
      "Completed iteration in 59.701101541519165\n",
      "Completed iteration in 60.22072982788086\n",
      "Completed iteration in 61.98526954650879\n",
      "Completed iteration in 69.58278965950012\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "\n",
    "f1_scores_only_2 = []\n",
    "for res in obj:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), res[1]))\n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores_only_2.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    \n",
    "    print(f\"Completed iteration in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-denial",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-strengthening",
   "metadata": {},
   "source": [
    "### Only lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "coupled-checklist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9754929661243792, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores_only_1), l[f1_scores_only_1.index(max(f1_scores_only_1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "focal-interval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4168872497992446, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores_only_2), l[f1_scores_only_2.index(max(f1_scores_only_2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-finnish",
   "metadata": {},
   "source": [
    "### All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "musical-consistency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9780804806233828, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores_all_1), l[f1_scores_all_1.index(max(f1_scores_all_1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "solar-tyler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5870088927222437, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores_all_2), l[f1_scores_all_2.index(max(f1_scores_all_2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-thong",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "collective-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "religious-trinidad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19707/2694940524.py:14: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "### PageRank distrib function\n",
    "serie = pd.Series(bet_l)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(serie, 200)\n",
    "plt.xlabel(\"Pagerank\", fontsize=22)\n",
    "plt.ylabel(\"Frequenza assoluta\", fontsize=22)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlim(-0.01, 1)\n",
    "\n",
    "plt.savefig(\"Distribution_norm_PageRank.png\", dpi=500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "spanish-miller",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19707/351606473.py:17: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "l = list(range(0, 10)) + list(range(10, 30, 2))\n",
    "plt.plot(l, f1_scores_all_1, \"o\", label=\"F1-score intervalli [b]\", markersize=10)\n",
    "plt.plot(l, f1_scores_all_2, \"o\", label=\"F1-score intervalli [c]\", markersize=10)\n",
    "\n",
    "plt.xlabel(\"Iterazione\", fontsize=22)\n",
    "plt.ylabel(\"F1-score\", fontsize=22)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.legend(loc=\"right\", prop={'size': 16})\n",
    "\n",
    "plt.savefig(\"Micro_comparison_allF_PageRank.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "progressive-channel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19707/717655246.py:17: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "l = list(range(0, 10)) + list(range(10, 30, 2))\n",
    "plt.plot(l, f1_scores_only_1, \"o\", label=\"F1-score intervalli [b]\", markersize=10)\n",
    "plt.plot(l, f1_scores_only_2, \"o\", label=\"F1-score intervalli [c]\", markersize=10)\n",
    "\n",
    "plt.xlabel(\"Iterazione\", fontsize=22)\n",
    "plt.ylabel(\"F1-score\", fontsize=22)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.legend(loc=\"right\", prop={'size': 16})\n",
    "\n",
    "plt.savefig(\"Micro_comparison_onlyL_PageRank.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "floating-scope",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19707/336782628.py:21: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "### With o and x\n",
    "plt.figure(figsize=(10, 6))\n",
    "l = list(range(0, 10)) + list(range(10, 30, 2))\n",
    "plt.plot(l, f1_scores_only_1, \"o\", label=\"AVPRA F1-score intervalli [b]\", markersize=10)\n",
    "plt.plot(l, f1_scores_only_2, \"o\", label=\"AVPRA F1-score intervalli [c]\", markersize=10)\n",
    "\n",
    "plt.plot(l, f1_scores_all_1, \"x\", label=\"AVPRA* F1-score intervalli [b]\", color=\"blue\", markersize=12)\n",
    "plt.plot(l, f1_scores_all_2, \"x\", label=\"AVPRA* F1-score intervalli [c]\", color=\"red\", markersize=12)\n",
    "\n",
    "plt.xlabel(\"Iterazione\", fontsize=22)\n",
    "plt.ylabel(\"F1-score\", fontsize=22)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.legend(loc=\"right\", prop={'size': 16})\n",
    "\n",
    "plt.savefig(\"Micro_comparison_both_PageRank.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eight-paris",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19707/112361814.py:21: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "### With o\n",
    "plt.figure(figsize=(10, 6))\n",
    "l = list(range(0, 10)) + list(range(10, 30, 2))\n",
    "plt.plot(l, f1_scores_only_1, \"o\", label=\"AVPRA F1-score intervalli [b]\", markersize=10)\n",
    "plt.plot(l, f1_scores_only_2, \"o\", label=\"AVPRA F1-score intervalli [c]\", markersize=10)\n",
    "\n",
    "plt.plot(l, f1_scores_all_1, \"o\", label=\"AVPRA* F1-score intervalli [b]\", markersize=10)\n",
    "plt.plot(l, f1_scores_all_2, \"o\", label=\"AVPRA* F1-score intervalli [c]\", markersize=10)\n",
    "\n",
    "plt.xlabel(\"Iterazione\", fontsize=22)\n",
    "plt.ylabel(\"F1-score\", fontsize=22)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.legend(loc=\"right\", prop={'size': 16})\n",
    "\n",
    "plt.savefig(\"Micro_comparison_both_O_PageRank.png\", dpi=500)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
