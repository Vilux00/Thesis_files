{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "genetic-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import useful libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import networkx as nx\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distinct-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"./EDGES_FILE.csv\", create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convenient-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "destroyed-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "l = list(nx.selfloop_edges(G))\n",
    "for x, _ in l:\n",
    "    if(G.degree(x) == 2): \n",
    "        G.remove_node(x)\n",
    "        nodes.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "million-potential",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(G.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "charged-excitement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated degrees in: 0.00011229515075683594\n"
     ]
    }
   ],
   "source": [
    "i_time = time.time()\n",
    "bet = nx.degree(G)\n",
    "print(f\"Calculated degrees in: {time.time() - i_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "authorized-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_l = []\n",
    "max_v = max(dict(bet).values())\n",
    "min_v = min(dict(bet).values())\n",
    "for i in sorted(list(map(lambda x: int(x), list(G.nodes())))):\n",
    "    bet_norm = (bet[str(i)] - min_v) / (max_v - min_v) \n",
    "    bet_l.append(bet_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confused-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.read_pickle(\"./AVPRA_pred.pickled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-nirvana",
   "metadata": {},
   "source": [
    "### Heterogeneous 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cognitive-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = []\n",
    "for bet_v in bet_l:\n",
    "    start_val = 0.0001\n",
    "    i = 1\n",
    "    while(True):\n",
    "        if bet_v <= start_val:\n",
    "            node_labels.append(i)\n",
    "            break\n",
    "        else:\n",
    "            i += 1\n",
    "            start_val *= 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inside-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    140\n",
       "21    139\n",
       "20    113\n",
       "19    100\n",
       "23     80\n",
       "18     60\n",
       "17     36\n",
       "16     29\n",
       "15     27\n",
       "24     20\n",
       "13     10\n",
       "14      9\n",
       "12      5\n",
       "11      4\n",
       "9       4\n",
       "1       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(node_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "comfortable-chambers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration completed in 0.14876961708068848\n",
      "Iteration completed in 0.1455073356628418\n",
      "Iteration completed in 0.20317316055297852\n",
      "Iteration completed in 0.1983191967010498\n",
      "Iteration completed in 0.20823407173156738\n",
      "Iteration completed in 0.20447468757629395\n",
      "Iteration completed in 0.18030881881713867\n",
      "Iteration completed in 0.17904067039489746\n",
      "Iteration completed in 0.17850303649902344\n",
      "Iteration completed in 0.18823027610778809\n",
      "Iteration completed in 0.173598051071167\n",
      "Iteration completed in 0.19966387748718262\n",
      "Iteration completed in 0.19762802124023438\n",
      "Iteration completed in 0.20221972465515137\n",
      "Iteration completed in 0.16446924209594727\n",
      "Iteration completed in 0.1712474822998047\n",
      "Iteration completed in 0.1674344539642334\n",
      "Iteration completed in 0.17160797119140625\n",
      "Iteration completed in 0.16859078407287598\n",
      "Iteration completed in 0.18669605255126953\n",
      "Iteration completed in 0.18907546997070312\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "f1_scores = []\n",
    "for res in obj:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), res[1]))\n",
    "    X_data = [X_data[i] for i in range(len(X_data)) if str(i + 1) not in nodes]\n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    print(f\"Iteration completed in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-attempt",
   "metadata": {},
   "source": [
    "### Heterogeneous 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "threatened-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = []\n",
    "for bet_v in bet_l:\n",
    "    ok = False\n",
    "    for i in range(1, 11):\n",
    "        if(bet_v <= 0.005 * i): \n",
    "            node_labels.append(i)\n",
    "            ok = True\n",
    "            break\n",
    "    if ok: continue\n",
    "    for i in range(1, 6):\n",
    "        if(bet_v <= 0.05 + 0.01 * i):\n",
    "            node_labels.append(10 + i)\n",
    "            ok = True\n",
    "            break\n",
    "    if ok: continue\n",
    "    if(bet_v <= 0.2):\n",
    "        node_labels.append(16)\n",
    "        continue\n",
    "    node_labels.append(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "relative-saint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    409\n",
       "16    179\n",
       "14     28\n",
       "13     20\n",
       "11     20\n",
       "5      19\n",
       "3      13\n",
       "12     13\n",
       "15     12\n",
       "8      12\n",
       "7      11\n",
       "1      10\n",
       "6       8\n",
       "9       8\n",
       "4       6\n",
       "2       5\n",
       "10      5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(node_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "harmful-process",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration completed in 0.10262012481689453\n",
      "Iteration completed in 0.1337568759918213\n",
      "Iteration completed in 0.19056129455566406\n",
      "Iteration completed in 0.18924164772033691\n",
      "Iteration completed in 0.17859578132629395\n",
      "Iteration completed in 0.1719827651977539\n",
      "Iteration completed in 0.1826319694519043\n",
      "Iteration completed in 0.18019509315490723\n",
      "Iteration completed in 0.17810511589050293\n",
      "Iteration completed in 0.16753911972045898\n",
      "Iteration completed in 0.18167471885681152\n",
      "Iteration completed in 0.19401240348815918\n",
      "Iteration completed in 0.16983985900878906\n",
      "Iteration completed in 0.16329264640808105\n",
      "Iteration completed in 0.1760258674621582\n",
      "Iteration completed in 0.16498637199401855\n",
      "Iteration completed in 0.17139244079589844\n",
      "Iteration completed in 0.18423962593078613\n",
      "Iteration completed in 0.17844223976135254\n",
      "Iteration completed in 0.16362571716308594\n",
      "Iteration completed in 0.17998862266540527\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "f1_scores2 = []\n",
    "for res in obj:\n",
    "    start_time = time.time()\n",
    "     \n",
    "    X_data = list(map(lambda x: sorted(x, reverse=True), res[1]))\n",
    "    X_data = [X_data[i] for i in range(len(X_data)) if str(i + 1) not in nodes]\n",
    "    y_data = node_labels\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    f1_scores2.append(metrics.f1_score(y_test, y_pred, average=\"micro\"))\n",
    "    print(f\"Iteration completed in {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "southwest-london",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2948717948717949, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores), (list(range(0, 10)) + list(range(10, 32, 2)))[f1_scores.index(max(f1_scores))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "understanding-defeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6089743589743589, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores2), (list(range(0, 10)) + list(range(10, 32, 2)))[f1_scores2.index(max(f1_scores2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-certification",
   "metadata": {},
   "source": [
    "### Graphs creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "chronic-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "altered-event",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26823/2006543703.py:17: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "l = list(range(0, 10)) + list(range(10, 32, 2))\n",
    "plt.plot(l, f1_scores, \"o\", label=\"F1-score intervalli [a]\", markersize=10)\n",
    "plt.plot(l, f1_scores2, \"o\", label=\"F1-score intervalli [b]\", markersize=10)\n",
    "\n",
    "plt.xlabel(\"Iterazione\", fontsize=22)\n",
    "plt.ylabel(\"F1-score\", fontsize=22)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.legend(loc=\"upper right\", prop={'size': 16})\n",
    "\n",
    "plt.savefig(\"Micro_comparison_Degree.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rubber-balloon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26823/3195118710.py:14: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "### Degree distrib function\n",
    "serie = pd.Series(bet_l)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(serie, 100)\n",
    "plt.xlabel(\"Grado\", fontsize=22)\n",
    "plt.ylabel(\"Frequenza assoluta\", fontsize=22)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlim(-0.01, 1)\n",
    "\n",
    "plt.savefig(\"Distribution_distrib_Degree.png\", dpi=500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-roberts",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
