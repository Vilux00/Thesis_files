{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "copyrighted-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import useful libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import networkx as nx\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-membership",
   "metadata": {},
   "source": [
    "### HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "printable-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading VLs from file\n",
    "obj = pd.read_pickle(\"./HR.pickled\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acting-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./HR_comms.txt\", sep=\" \", header=None)\n",
    "comms_dict = {}\n",
    "for row in data.iterrows():\n",
    "    comms_dict[str(row[1][0])] = row[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "democratic-island",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration completed in 4.431243896484375\n",
      "Iteration completed in 12.981043577194214\n",
      "Iteration completed in 20.591996669769287\n",
      "Iteration completed in 23.150129079818726\n",
      "Iteration completed in 25.824406147003174\n",
      "Iteration completed in 26.07561683654785\n",
      "Iteration completed in 26.873189449310303\n",
      "Iteration completed in 27.52234721183777\n",
      "Iteration completed in 28.056808948516846\n",
      "Iteration completed in 27.064818143844604\n",
      "Iteration completed in 27.81883955001831\n",
      "Iteration completed in 27.21990466117859\n",
      "Iteration completed in 26.774442434310913\n",
      "Iteration completed in 27.287861108779907\n",
      "Iteration completed in 26.69911241531372\n",
      "Iteration completed in 27.022515058517456\n",
      "Iteration completed in 26.242228269577026\n",
      "Iteration completed in 26.259974718093872\n",
      "Iteration completed in 26.122005939483643\n",
      "Iteration completed in 26.56774377822876\n",
      "Iteration completed in 25.257197380065918\n"
     ]
    }
   ],
   "source": [
    "### Random forest classifier creation with 70 trees\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "start_time = time.time()\n",
    "accuracies = []\n",
    "f1_scores_macro = []\n",
    "f1_scores_weigh = []\n",
    "for res in obj:\n",
    "    s_time = time.time()\n",
    "    # Input \n",
    "    X_data = res[1]\n",
    "    # Output communities defined by Louvain algorithm\n",
    "    y_data = [comms_dict.get(str(i)) for i in range(1, len(comms_dict) + 1)]\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    accuracies.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    f1_scores_macro.append(metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    f1_scores_weigh.append(metrics.f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "\n",
    "    print(f\"Iteration completed in {time.time() - s_time}\")\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "noticed-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function that returns the 10 / 1 index of the maximum values of a list\n",
    "def get10maxidx(l):\n",
    "    return list(map(lambda x: x[1], sorted(zip(l, range(0, len(l))), reverse=True)[:10]))\n",
    "def getmaxidx(l):\n",
    "    return l.index(max(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specialized-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10MWL classification\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "start_time2 = time.time()\n",
    "accuracies2 = []\n",
    "f1_scores2_macro = []\n",
    "f1_scores2_weigh = []\n",
    "for res in obj:\n",
    "    # Input \n",
    "    X_data = list(map(lambda x: get10maxidx(x), res[1]))\n",
    "\n",
    "    # Output communities defined by Louvain algorithm\n",
    "    y_data = [comms_dict.get(str(i)) for i in range(1, len(comms_dict) + 1)]\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    accuracies2.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    f1_scores2_macro.append(metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    f1_scores2_weigh.append(metrics.f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "    \n",
    "end_time2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "empirical-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MWL classification\n",
    "clf = RandomForestClassifier(n_estimators=70)\n",
    "start_time3 = time.time()\n",
    "accuracies3 = []\n",
    "f1_scores3_macro = []\n",
    "f1_scores3_weigh = []\n",
    "for res in obj:\n",
    "    # Input \n",
    "    X_data = list(map(lambda x: [getmaxidx(x)], res[1]))\n",
    "\n",
    "    # Output communities defined by Louvain algorithm\n",
    "    y_data = [comms_dict.get(str(i)) for i in range(1, len(comms_dict) + 1)]\n",
    "\n",
    "    # Split the data into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    ### Accuracy metric\n",
    "    accuracies3.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    f1_scores3_macro.append(metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    f1_scores3_weigh.append(metrics.f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "    \n",
    "end_time3 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "welsh-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-cycle",
   "metadata": {},
   "source": [
    "### Comparison macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "functional-latin",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15942/633048183.py:18: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Plot F1-macro comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "l = list(range(0,10)) + list(range(10, 32, 2))\n",
    "plt.plot(l, f1_scores_macro, \"o\", label=\"AVPRA F1-score-macro\", markersize=10)\n",
    "plt.plot(l, f1_scores2_macro, \"o\", label=\"AVPRA 10MWL F1-score-macro\", markersize=10)\n",
    "plt.plot(l, f1_scores3_macro, \"o\", label=\"AVPRA MWL F1-score-macro\", markersize=10)\n",
    "\n",
    "plt.axvline(x=12, label=\"Diametro\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Iterazione\", fontsize=20)\n",
    "plt.ylabel(\"F1-score\", fontsize=20)\n",
    "plt.legend(loc=\"right\", prop={'size': 16})\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.savefig(\"F1_HR_AVPRA_all_macro.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distinct-memorial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.934652928358529, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores_macro), (list(range(0,10)) + list(range(10, 32, 2)))[f1_scores_macro.index(max(f1_scores_macro))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "waiting-backing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33598107579833747, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores2_macro), (list(range(0,10)) + list(range(10, 32, 2)))[f1_scores2_macro.index(max(f1_scores2_macro))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spatial-startup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.039308119147952014, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores3_macro), (list(range(0,10)) + list(range(10, 32, 2)))[f1_scores3_macro.index(max(f1_scores3_macro))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-surface",
   "metadata": {},
   "source": [
    "### Comparison weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sticky-unknown",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15942/1808850347.py:18: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Plot F1-macro comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "l = list(range(0,10)) + list(range(10, 32, 2))\n",
    "plt.plot(l, f1_scores_weigh, \"o\", label=\"AVPRA F1-score-weighted\", markersize=10)\n",
    "plt.plot(l, f1_scores2_weigh, \"o\", label=\"AVPRA 10MWL F1-score-weighted\", markersize=10)\n",
    "plt.plot(l, f1_scores3_weigh, \"o\", label=\"AVPRA MWL F1-score-weighted\", markersize=10)\n",
    "\n",
    "plt.axvline(x=12, label=\"Diametro\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Iterazione\", fontsize=20)\n",
    "plt.ylabel(\"F1-score\", fontsize=20)\n",
    "plt.legend(loc=\"right\", prop={'size': 16})\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.savefig(\"F1_HR_AVPRA_all_weighted.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "twenty-transfer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9312446539501439, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores_weigh), (list(range(0,10)) + list(range(10, 32, 2)))[f1_scores_weigh.index(max(f1_scores_weigh))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "enhanced-murder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37026009679725896, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores2_weigh), (list(range(0,10)) + list(range(10, 32, 2)))[f1_scores2_weigh.index(max(f1_scores2_weigh))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sensitive-product",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05766769306158939, 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f1_scores3_weigh), (list(range(0,10)) + list(range(10, 32, 2)))[f1_scores3_weigh.index(max(f1_scores3_weigh))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "under-vintage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15942/2264449537.py:17: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Plot accuracy graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "l = list(range(0,10)) + list(range(10, 32, 2))\n",
    "plt.plot(l, accuracies, \"o\", label=\"AVPRA Accuratezza\", markersize=10)\n",
    "plt.plot(l, f1_scores_macro, \"x\", label=\"AVPRA F1-score-macro\", color=\"blue\", markersize=12)\n",
    "\n",
    "plt.axvline(x=12, label=\"Diametro\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Iterazione\", fontsize=20)\n",
    "plt.ylabel(\"Accuratezza/F1-Score\", fontsize=20)\n",
    "plt.legend(loc=\"right\", prop={'size': 16})\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.savefig(\"F1_HR_AVPRA_macro.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "express-consensus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15942/4075143853.py:17: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Plot accuracy graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "l = list(range(0,10)) + list(range(10, 32, 2))\n",
    "plt.plot(l, accuracies, \"o\", label=\"AVPRA Accuratezza\", markersize=10)\n",
    "plt.plot(l, f1_scores_weigh, \"x\", label=\"AVPRA F1-score-weighted\", color=\"blue\", markersize=12)\n",
    "\n",
    "plt.axvline(x=12, label=\"Diametro\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Iterazione\", fontsize=20)\n",
    "plt.ylabel(\"Accuratezza/F1-Score\", fontsize=20)\n",
    "plt.legend(loc=\"right\", prop={'size': 16})\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.savefig(\"F1_HR_AVPRA_weighted.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "current-accent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9310123683005039, 16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracies), l[accuracies.index(max(accuracies))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beginning-combination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.416491067338525, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracies2), l[accuracies2.index(max(accuracies2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "greek-wallpaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15959688502061384, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracies3), l[accuracies3.index(max(accuracies3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beneficial-detective",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15942/3210136815.py:18: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Plot accuracy graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "l = list(range(0,10)) + list(range(10, 32, 2))\n",
    "plt.plot(l, accuracies, \"o\", label=\"AVPRA Accuratezza\", markersize=10)\n",
    "plt.plot(l, accuracies2, \"o\", label=\"AVPRA 10MWL Accuratezza\", markersize=10)\n",
    "plt.plot(l, accuracies3, \"o\", label=\"AVPRA MWL Accuratezza\", markersize=10)\n",
    "\n",
    "plt.axvline(x=12, label=\"Diametro\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Iterazione\", fontsize=20)\n",
    "plt.ylabel(\"Accuratezza\", fontsize=20)\n",
    "plt.legend(loc=\"right\", prop={'size': 16})\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.savefig(\"F1_comparisons_HR.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-client",
   "metadata": {},
   "source": [
    "### Only F1 micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "descending-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15942/3124994506.py:16: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Plot accuracy graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "l = list(range(0,10)) + list(range(10, 32, 2))\n",
    "plt.plot(l, accuracies, \"o\", label=\"AVPRA Accuratezza\", markersize=10)\n",
    "\n",
    "plt.axvline(x=12, label=\"Diametro\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Iterazione\", fontsize=20)\n",
    "plt.ylabel(\"Accuratezza\", fontsize=20)\n",
    "plt.legend(loc=\"right\", prop={'size': 16})\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.savefig(\"F1_HR_AVPRA_micro.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-cache",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-coaching",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
